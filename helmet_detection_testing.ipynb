{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python==4.1.2.30 in c:\\users\\ragav\\anaconda3\\envs\\mask_detection\\lib\\site-packages (4.1.2.30)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from opencv-python==4.1.2.30) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python==4.1.2.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.14.0 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (1.14.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (0.8.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (1.22.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\ragav\\anaconda3\\envs\\mask_detection\\lib\\site-packages (from tensorflow==1.14.0) (0.36.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\ragav\\anaconda3\\envs\\mask_detection\\lib\\site-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (0.1.7)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ragav\\anaconda3\\envs\\mask_detection\\lib\\site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\ragav\\anaconda3\\envs\\mask_detection\\lib\\site-packages (from tensorflow==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (3.9.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (0.7.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ragav\\anaconda3\\envs\\mask_detection\\lib\\site-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\ragav\\appdata\\roaming\\python\\python36\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.15.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# It loads the classifier uses it to perform object detection on a webcam feed.\n",
    "# It draws boxes and scores around the objects of interest in each frame from\n",
    "# the webcam.\n",
    "\n",
    "# Import packages\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_graphs/frozen_inference_graph.pb\n"
     ]
    }
   ],
   "source": [
    "detection_graph = tf.Graph()\n",
    "\n",
    "\n",
    "# Import utilites\n",
    "# from utils import label_map_util\n",
    "\n",
    "# Name of the directory containing the object detection module we're using\n",
    "TRAINED_MODEL_DIR = 'frozen_graphs'\n",
    "\n",
    "# Path to frozen detection graph .pb file, which contains the model that is used\n",
    "# for object detection.\n",
    "PATH_TO_CKPT = TRAINED_MODEL_DIR + '/frozen_inference_graph.pb'\n",
    "print(PATH_TO_CKPT)\n",
    "# Path to label map file\n",
    "PATH_TO_LABELS = TRAINED_MODEL_DIR + '/labelmap.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0611 08:50:22.249634 27568 deprecation_wrapper.py:119] From C:\\Users\\ragav\\Downloads\\helmet_detection_final\\utils\\label_map_util.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'id': 1, 'name': 'with_helmet'}}\n"
     ]
    }
   ],
   "source": [
    "# Number of classes the object detector can identify\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "print(category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ====== Loading frozen graph into memory\n",
      ">  ====== Inference graph loaded.\n"
     ]
    }
   ],
   "source": [
    "print(\"> ====== Loading frozen graph into memory\")\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "    sess = tf.Session(graph=detection_graph)\n",
    "    print(\">  ====== Inference graph loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input tensor is the image\n",
    "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "\n",
    "# Output tensors are the detection boxes, scores, and classes\n",
    "# Each box represents a part of the image where a particular object was detected\n",
    "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "# Each score represents level of confidence for each of the objects.\n",
    "# The score is shown on the result image, together with the class label.\n",
    "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "\n",
    "# Number of objects detected\n",
    "num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "print(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'detection_boxes:0' shape=<unknown> dtype=float32>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('image4.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3728400"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1680000\n",
      "(700, 800, 3)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.resize(image, (800,700))\n",
    "image_expanded = np.expand_dims(image, axis=0)\n",
    "print(image.size)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names_mapping = {\n",
    "            1: \"with_helmet\",2:\"motorcycle\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "(boxes, scores, classes, num) = sess.run(\n",
    "            [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "            feed_dict={image_tensor: image_expanded})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = scores.flatten()\n",
    "res = []\n",
    "for idx in range(0, len(result)):\n",
    "    if result[idx] > .40:\n",
    "        res.append(idx)\n",
    "\n",
    "top_classes = classes.flatten()\n",
    "# Selecting class 2 and 3\n",
    "#top_classes = top_classes[top_classes > 1]\n",
    "res_list = [top_classes[i] for i in res]\n",
    "\n",
    "class_final_names = [class_names_mapping[x] for x in res_list]\n",
    "top_scores = [e for l2 in scores for e in l2 if e > 0.30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9994969e-01, 9.9989414e-01, 1.9424933e-03, 1.8327813e-04,\n",
       "       5.6751942e-05, 3.6621797e-05, 3.2412467e-05, 3.2117146e-05,\n",
       "       2.2014267e-05, 1.2585371e-05, 1.0615051e-05, 8.4403691e-06,\n",
       "       7.3463711e-06, 6.9216871e-06, 6.4415744e-06, 5.6095905e-06,\n",
       "       4.3096707e-06, 3.8491030e-06, 3.1485131e-06, 3.0594674e-06,\n",
       "       2.8681518e-06, 2.5539284e-06, 2.4382496e-06, 2.2991226e-06,\n",
       "       2.2960244e-06, 1.7156862e-06, 1.5893220e-06, 1.3152633e-06,\n",
       "       1.2326932e-06, 1.1697202e-06, 1.0246614e-06, 1.0114248e-06,\n",
       "       9.6525548e-07, 8.9149978e-07, 8.5885023e-07, 8.4856271e-07,\n",
       "       8.3783561e-07, 7.9306528e-07, 7.1229857e-07, 7.0502728e-07,\n",
       "       6.6278767e-07, 6.5945238e-07, 6.2902353e-07, 6.2260352e-07,\n",
       "       5.9501838e-07, 5.7159093e-07, 5.5793481e-07, 5.3533103e-07,\n",
       "       5.2216217e-07, 3.9653565e-07, 3.9184823e-07, 3.8484316e-07,\n",
       "       3.8178527e-07, 3.5515615e-07, 3.3651492e-07, 3.1467820e-07,\n",
       "       3.0670788e-07, 2.9830062e-07, 2.9759232e-07, 2.9219478e-07,\n",
       "       2.8253856e-07, 2.7687804e-07, 2.7573731e-07, 2.4895590e-07,\n",
       "       2.3933271e-07, 2.3452371e-07, 2.1667837e-07, 2.0758318e-07,\n",
       "       1.9805874e-07, 1.9491377e-07, 1.9477923e-07, 1.7655404e-07,\n",
       "       1.6416628e-07, 1.6009550e-07, 1.5554146e-07, 1.4807091e-07,\n",
       "       1.4559203e-07, 1.3771354e-07, 1.3637822e-07, 1.3233530e-07,\n",
       "       1.1628194e-07, 8.8714152e-08, 8.3885276e-08, 8.0181564e-08,\n",
       "       7.7809858e-08, 7.3444134e-08, 7.3266868e-08, 6.4997074e-08,\n",
       "       6.4036634e-08, 5.2347392e-08, 5.1264845e-08, 4.9440569e-08,\n",
       "       3.7273459e-08, 3.4013304e-08, 3.3725186e-08, 3.1697475e-08,\n",
       "       2.6724248e-08, 1.9260872e-08, 1.9072493e-08, 1.6810530e-08,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scores = scores.flatten()\n",
    "\n",
    "new_boxes = boxes.reshape(300, 4)\n",
    "\n",
    "# get all boxes from an array\n",
    "max_boxes_to_draw = new_boxes.shape[0]\n",
    "# this is set as a default but feel free to adjust it to your needs\n",
    "min_score_thresh = .30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "    image,\n",
    "    np.squeeze(boxes),\n",
    "    np.squeeze(classes).astype(np.int32),\n",
    "    np.squeeze(scores),\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    line_thickness=6,\n",
    "    min_score_thresh=0.30)\n",
    "cv2.imshow('Object detector', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Object detector', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-dc7c6c126490>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Selecting class 2 and 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtop_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtop_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_classes\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mres_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtop_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mclass_final_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_names_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-dc7c6c126490>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Selecting class 2 and 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtop_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtop_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_classes\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mres_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtop_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mclass_final_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_names_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "result = scores.flatten()\n",
    "res = []\n",
    "for idx in range(0, len(result)):\n",
    "    if result[idx] > .40:\n",
    "        res.append(idx)\n",
    "\n",
    "top_classes = classes.flatten()\n",
    "# Selecting class 2 and 3\n",
    "#top_classes = top_classes[top_classes > 1]\n",
    "res_list = [top_classes[i] for i in res]\n",
    "\n",
    "class_final_names = [self.class_names_mapping[x] for x in res_list]\n",
    "top_scores = [e for l2 in scores for e in l2 if e > 0.30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-d0fc8fd960dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mplaysound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\ragav\\OneDrive\\Pictures\\ineuron notes\\face_\\alert.wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Object detector'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in classes_flat2:\n",
    "    if i == 2:\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8,\n",
    "        min_score_thresh=0.75)\n",
    "#         cv2.putText(image, text, org, font, fontScale, \n",
    "#                  color, thickness, cv2.LINE_AA, False)\n",
    "        cv2.putText(image, \"ALERT\",(0, 180),cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0,255), 2)\n",
    "        playsound(r\"C:\\Users\\ragav\\OneDrive\\Pictures\\ineuron notes\\face_\\alert.wav\")\n",
    "        cv2.imshow('Object detector', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hjeeekjekjkjek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8,\n",
    "        min_score_thresh=0.75)\n",
    "    # All the results have been drawn on the frame, so it's time to display it.\n",
    "cv2.imshow('Object detector', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = scores.flatten()\n",
    "res = []\n",
    "for idx in range(0, len(result)):\n",
    "    if result[idx] > .40:\n",
    "        res.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=np.squeeze(classes).astype(np.int32).flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.flatten>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
